from google import genai
from google.genai import types
import streamlit as st
import PIL.Image

class GeminiClient:
    def __init__(self, api_key=None):
        self.api_key = api_key or st.secrets.get("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("æœªæ‰¾åˆ° Gemini API Key")
        
        try:
            self.client = genai.Client(api_key=self.api_key)
            
            # --- ğŸ”¥ æ ¸å¿ƒæ”¹å˜ï¼šä¸å†ç¡¬ç¼–ç ï¼Œè€Œæ˜¯è‡ªåŠ¨å¯»æ‰¾æœ€ä½³æ¨¡å‹ ---
            self.model_name = self._get_best_available_model()
            
            print(f"DEBUG: æœ€ç»ˆé€‰å®šçš„æ¨¡å‹æ˜¯: {self.model_name}")

        except Exception as e:
            print(f"ERROR: å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise e

    def _get_best_available_model(self):
        """
        è‡ªåŠ¨æŸ¥è¯¢ API Key æ”¯æŒçš„æ‰€æœ‰æ¨¡å‹ï¼Œå¹¶æŒ‰ä¼˜å…ˆçº§é€‰æ‹©æœ€å¥½çš„ã€‚
        """
        try:
            print("DEBUG: æ­£åœ¨å‘ Google æŸ¥è¯¢å¯ç”¨æ¨¡å‹åˆ—è¡¨...")
            # 1. è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹
            all_models_iterator = self.client.models.list()
            # æå–æ”¯æŒ generateContent çš„æ¨¡å‹åç§°
            available_models = []
            for m in all_models_iterator:
                # æ–°ç‰ˆ SDK çš„ model å¯¹è±¡é€šå¸¸åŒ…å« supported_generation_methods
                if hasattr(m, 'supported_generation_methods') and 'generateContent' in m.supported_generation_methods:
                    available_models.append(m.name)
                # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœå±æ€§åä¸åŒï¼Œæˆ–è€…é»˜è®¤éƒ½æ”¯æŒ
                elif hasattr(m, 'name'):
                    available_models.append(m.name)

            print(f"DEBUG: Google è¿”å›äº† {len(available_models)} ä¸ªå¯ç”¨æ¨¡å‹: {available_models}")

            # 2. å®šä¹‰ä¼˜å…ˆçº§ï¼šæˆ‘ä»¬æƒ³è¦æœ€å¼ºçš„é€»è¾‘ (Pro)ï¼Œå…¶æ¬¡æ˜¯ Flash
            # æ³¨æ„ï¼šGoogle è¿”å›çš„åå­—é€šå¸¸æ˜¯ "models/gemini-1.5-pro-001" è¿™ç§å…¨ç§°
            priority_keywords = [
                "gemini-1.5-pro-002", # æœ€å¼ºé€»è¾‘
                "gemini-1.5-pro",     # é€šç”¨ Pro
                "gemini-1.5-pro-latest",
                "gemini-1.5-pro-001",
                "gemini-2.0-flash",   # æ–°ç‰ˆ Flash (ä½œä¸º Pro çš„å¤‡é€‰)
                "gemini-1.5-flash",   # æ—§ç‰ˆ Flash
                "gemini-pro"          # æœ€è€çš„ Pro
            ]

            # 3. åŒ¹é…é€»è¾‘
            for keyword in priority_keywords:
                for real_name in available_models:
                    # å¦‚æœå…³é”®è¯åœ¨çœŸåé‡Œï¼ˆä¾‹å¦‚ "gemini-1.5-pro" åœ¨ "models/gemini-1.5-pro-001" é‡Œï¼‰
                    if keyword in real_name:
                        return real_name # ç›´æ¥è¿”å›è¿™ä¸ªç™¾åˆ†ç™¾å­˜åœ¨çš„çœŸå

            # 4. å¦‚æœæ²¡æ‰¾åˆ°ä»»ä½•å¿ƒä»ªçš„ï¼Œå°±æ‹¿åˆ—è¡¨é‡Œç¬¬ä¸€ä¸ªèƒ½ç”¨çš„
            if available_models:
                return available_models[0]
            
            # 5. ç»æœ›å…œåº•ï¼ˆå¦‚æœ list å¤±è´¥äº†ï¼Œè¿˜æ˜¯å¾—è¯•ä¸€ä¸ªï¼‰
            return "gemini-1.5-flash"

        except Exception as e:
            print(f"WARN: è‡ªåŠ¨ä¾¦æµ‹æ¨¡å‹å¤±è´¥ ({e})ï¼Œå›é€€åˆ°å®‰å…¨æ¨¡å¼ã€‚")
            return "gemini-1.5-flash"

    def _compress_image(self, image_file):
        try:
            if hasattr(image_file, 'seek'):
                image_file.seek(0)
            img = PIL.Image.open(image_file).convert('RGB')
            max_size = 800
            if max(img.size) <= max_size:
                return img
            img.thumbnail((max_size, max_size))
            return img
        except Exception as e:
            if hasattr(image_file, 'seek'):
                image_file.seek(0)
            return PIL.Image.open(image_file)

    def _build_history(self, chat_history):
        contents = []
        for msg in chat_history:
            if "image" in msg and msg["image"]:
                continue
            role = "user" if msg["role"] == "user" else "model"
            if isinstance(msg["content"], str):
                contents.append(types.Content(
                    role=role,
                    parts=[types.Part.from_text(text=msg["content"])]
                ))
        return contents

    def generate_content(self, prompt, chat_history=[]):
        try:
            history_contents = self._build_history(chat_history)
            history_contents.append(types.Content(
                role="user",
                parts=[types.Part.from_text(text=prompt)]
            ))
            
            # ä½¿ç”¨è‡ªåŠ¨ä¾¦æµ‹åˆ°çš„ model_name
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=history_contents
            )
            return response.text
        except Exception as e:
            return f"è¯·æ±‚å¤±è´¥ (Model: {self.model_name}): {str(e)}"

    def analyze_image(self, image_file, prompt="è¯·æè¿°è¿™å¼ å›¾ç‰‡"):
        try:
            img = self._compress_image(image_file)
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=[prompt, img]
            )
            return response.text
        except Exception as e:
            return f"å›¾ç‰‡åˆ†æå¤±è´¥ (Model: {self.model_name}): {str(e)}"

